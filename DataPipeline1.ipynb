{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6237779",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from dagster import op, In, Out, graph\n",
    "from typing import List\n",
    "import yfinance as yf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fd29a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "@op(ins={\"ticker\": In(dagster_type=str)}, out=Out(pd.DataFrame))\n",
    "\n",
    "def download_data(context, ticker: str) -> pd.DataFrame:\n",
    "    # Calculate start and end dates for the download\n",
    "    end_date = datetime.now().date()\n",
    "    start_date = end_date - timedelta(days=1)\n",
    "    \n",
    "    # Download the data for the ticker\n",
    "    data = yf.download(ticker, start=start_date, end=end_date, interval=\"1m\")\n",
    "    \n",
    "    # Filter to yesterday's date\n",
    "    yesterday = (datetime.now() - timedelta(days=1)).date()\n",
    "    data = data.loc[data.index.date == yesterday]\n",
    "    \n",
    "    # Add column for ticker symbol\n",
    "    data['Ticker'] = ticker\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36fc7f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@op(out=Out(str))\n",
    "def get_netflix() -> str:\n",
    "    return \"NFLX\"\n",
    "\n",
    "@op(out=Out(str))\n",
    "def get_disney() -> str:\n",
    "    return \"DIS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "120479cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@op(ins={\"data\": In(dagster_type=pd.DataFrame)}, out=Out(pd.DataFrame))\n",
    "def validate_data(context, data: pd.DataFrame) -> pd.DataFrame:\n",
    "    if data.empty:\n",
    "        context.log.error(f\"Data invalid for ticker: {data.iloc[0]['Ticker']}\")\n",
    "        return data\n",
    "    else:\n",
    "        context.log.error(f\"Data valid for ticker: {data.iloc[0]['Ticker']}\")\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93eae69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@op(ins={\"data\": In(dagster_type=pd.DataFrame)}, out=Out(pd.DataFrame))\n",
    "def clean_data(context, data: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Remove \"Adj Close\" column from data\n",
    "    data.drop(\"Adj Close\", axis=1, inplace=True)\n",
    "    \n",
    "    # Return the updated data frame\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9fd39a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@op(ins={\"data\": In(dagster_type=pd.DataFrame)}, out=Out(pd.DataFrame))\n",
    "\n",
    "def transform_data(context, data: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Columns needed to determine rolling VWAP\n",
    "    data['Typical Price'] = (data['High'] + data['Low'] + data['Close']) / 3\n",
    "    data['Cumulative TPV'] = data['Typical Price'] * data['Volume']\n",
    "    data['Cumulate Volume'] = data['Volume'].cumsum()\n",
    "    data['Rolling TPV'] = data['Cumulative TPV'].rolling('15min', min_periods=1).sum()\n",
    "    data['Rolling Volume'] = data['Volume'].rolling('15min', min_periods=1).sum()\n",
    "    \n",
    "    # Add the rolling VWAP to the data frame\n",
    "    data['VWAP'] = data['Rolling TPV'] / data['Rolling Volume']\n",
    "    \n",
    "    # Remove unneeded temporary columns\n",
    "    data.drop(['Typical Price',\n",
    "               'Rolling Volume',\n",
    "               'Cumulative TPV',\n",
    "               'Cumulative Volume',\n",
    "               'Rolling TPV'], axis=1, inplace=True)\n",
    "    \n",
    "    # Calculate the cumulative dollar value of all trades\n",
    "    dollar_value = (data['Close'] * data['Volume']).cumsum()\n",
    "    \n",
    "    # Add the dollar value column to the data data frame\n",
    "    data['DollarValue'] = dollar_value\n",
    "    \n",
    "    # Return the udpated data frame\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93543ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@op(ins={\"dfs\": In(dagster_type=List[pd.DataFrame])})\n",
    "def write_to_csv(context, dfs):\n",
    "    # Combine different datasets\n",
    "    data = pd.concat(dfs, ignore_index=False).sort_values(\"Datetime\")\n",
    "    \n",
    "    # Get the daily date of the data\n",
    "    filepath = f\"./{str(data.index[0].date())}.csv\"\n",
    "    \n",
    "    # Write the transformed data to a CSV file\n",
    "    data.to_csv(filepath)\n",
    "    \n",
    "    # Log a message to confirm that the data has been written to the file\n",
    "    context.log.info(f\"Data written to file: {filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0e5ca8",
   "metadata": {},
   "source": [
    "## Building the pipeline\n",
    "\n",
    "### Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3542ecc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@graph\n",
    "def collection_pipeline(ticker: str):\n",
    "    # Get data for ticker\n",
    "    data = download_data(ticker)\n",
    "    \n",
    "    # Ensure data is valid and clean\n",
    "    data = clean_data(validate_data(data))\n",
    "    \n",
    "    # Enrich data\n",
    "    data = transform_data(data)\n",
    "    \n",
    "    return data\n",
    "\n",
    "@graph\n",
    "def running_pipeline():\n",
    "    data_nflx = collection_pipeline(get_netflix())\n",
    "    data_dis = collection_pipeline(get_disney())\n",
    "    \n",
    "    # Save the combined datasets to one location\n",
    "    write_to_csv([data_nflx, data_dis])\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063442c0",
   "metadata": {},
   "source": [
    "### Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629c3ee9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
